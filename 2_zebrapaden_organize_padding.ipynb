{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import shutil\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "from os.path import join\n",
    "import tifffile\n",
    "import cv2\n",
    "import math\n",
    "from osgeo import gdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is required for me to have autocomplete\n",
    "%config Completer.use_jedi = False\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables for dataset size\n",
    "large_size = 400\n",
    "medium_size = 350\n",
    "small_size = 300\n",
    "\n",
    "# set variables for padding\n",
    "model_divisor = 32\n",
    "BLACK = [0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create trainset folders if they don't exist\n",
    "# sizes \n",
    "sizes = [\"small\",\"medium\",\"large\",\"small_transform\",\"medium_transform\",\"large_transform\"]\n",
    "\n",
    "# media\n",
    "media = [\"annotations\",\"images\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/trainset/small/annotations\n",
      "data/trainset/small/images\n",
      "data/trainset/medium/annotations\n",
      "data/trainset/medium/images\n",
      "data/trainset/large/annotations\n",
      "data/trainset/large/images\n",
      "data/trainset/small_transform/annotations\n",
      "data/trainset/small_transform/images\n",
      "data/trainset/medium_transform/annotations\n",
      "data/trainset/medium_transform/images\n",
      "data/trainset/large_transform/annotations\n",
      "data/trainset/large_transform/images\n"
     ]
    }
   ],
   "source": [
    "# create folder tree for trainset\n",
    "trainset_path = \"data/trainset/\"\n",
    "\n",
    "for size in sizes:\n",
    "    for med in media:\n",
    "        path = trainset_path+size+\"/\"+med\n",
    "        print(path)\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        \n",
    "\n",
    "# create first large folder for original tifs\n",
    "os.makedirs(trainset_path+\"large/\"+\"tifs/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set paths: original tif and annotation folder\n",
    "# raw annotations and starting tiffs\n",
    "tif_folder = \"data/1_set_tiffs/\"\n",
    "ann_raw_folder = \"data/1_set_raw_annotated/\"\n",
    "\n",
    "# starting tiffs from 0-set (no annotations of course)\n",
    "tif_folder_0 = \"data/0_set_tiffs/\"\n",
    "\n",
    "\n",
    "# set paths: transet folders\n",
    "# output folder for tiffs and annotations, large dataset\n",
    "ann_out_path = \"data/trainset/large/annotations/\"\n",
    "tif_out_path = \"data/trainset/large/tifs/\"\n",
    "\n",
    "# output folder for png images from tifs\n",
    "im_out_path = \"data/trainset/large/images/\"\n",
    "\n",
    "# tiff and annotation paths for medium set (drawn from large)\n",
    "im_path_m = \"data/trainset/medium/images/\"\n",
    "ann_path_m = \"data/trainset/medium/annotations/\"\n",
    "\n",
    "# tiff and annotations paths for small set (drawn from medium)\n",
    "im_path_s = \"data/trainset/small/images/\"\n",
    "ann_path_s = \"data/trainset/small/annotations/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create large train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Place annotations & add corresponding tiffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all zip files\n",
    "ann_raw_paths = [join(ann_raw_folder,f) for f in os.listdir(ann_raw_folder) if f.endswith('.zip')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all content of Segmentationclass folder for each zip\n",
    "for filepath in ann_raw_paths:\n",
    "    obj = ZipFile(filepath, 'r')\n",
    "    filelist = obj.namelist()\n",
    "    for file in filelist:\n",
    "        if file.startswith(\"SegmentationClass\"):\n",
    "            obj.extract(file, path=ann_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move all files 1 level up\n",
    "segmentation_path = os.listdir(ann_out_path+\"SegmentationClass\")\n",
    "\n",
    "for mask in segmentation_path:\n",
    "    shutil.move(ann_out_path+\"SegmentationClass/\"+mask, ann_out_path+mask)\n",
    "    \n",
    "# remove folder\n",
    "os.removedirs(ann_out_path+\"SegmentationClass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list id's of annotated tifs\n",
    "tif_id = [re.sub(\"\\.png$\",\"\",l) for l in os.listdir(ann_out_path)]\n",
    "tif_list = [tif_folder+t+\".tif\" for t in tif_id]\n",
    "tif_out_list = [tif_out_path+t+\".tif\" for t in tif_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy tifs to largefolder\n",
    "for tif, tif_out in zip(tif_list, tif_out_list):\n",
    "    shutil.copy(tif, tif_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Place random draw from 0-set tiffs and create empty annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tiff sample 800\n",
    "neg_tiffs = os.listdir(tif_folder_0)\n",
    "neg_tiffs = random.sample(neg_tiffs, large_size*2)\n",
    "\n",
    "# create new tiff ID so they don't clash with existing tifs, and we know its 0-set\n",
    "neg_tiff_id = [\"negset_\"+l for l in neg_tiffs]\n",
    "\n",
    "#create new annotation ID as well\n",
    "neg_ann_id = [re.sub(\"\\.tif$\",\".png\", l) for l in neg_tiff_id]\n",
    "\n",
    "# create full paths\n",
    "neg_full_in = [tif_folder_0+l for l in neg_tiffs]\n",
    "neg_full_out = [tif_out_path+l for l in neg_tiff_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy tifs to large folder\n",
    "for tif_in, tif_out in zip(neg_full_in, neg_full_out):\n",
    "    shutil.copy(tif_in, tif_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 0-set annotations\n",
    "\n",
    "# get size of sample image\n",
    "neg_array = tifffile.imread(tif_out_path+neg_tiff_id[0])\n",
    "\n",
    "# make all black array for mask\n",
    "neg_array.fill(0)\n",
    "\n",
    "# create full annotation path\n",
    "neg_annotation_paths = [ann_out_path+re.sub(\"\\.tif$\",\".png\", l) for l in neg_tiff_id]\n",
    "\n",
    "for annotation in neg_annotation_paths:\n",
    "    cv2.imwrite(annotation, neg_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pad images and annotations in large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [tif_out_path+l for l in os.listdir(tif_out_path)]\n",
    "annotation_paths = [ann_out_path+l for l in os.listdir(ann_out_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im in image_paths:\n",
    "    # read image\n",
    "    image = tifffile.imread(im)\n",
    "    \n",
    "    # calculate padding size\n",
    "    modulo_h = image.shape[1] % model_divisor\n",
    "    modulo_v = image.shape[0] % model_divisor\n",
    "    \n",
    "    if(modulo_h == 0)&(modulo_v == 0):\n",
    "        continue\n",
    "    \n",
    "    padding_size_h = model_divisor-modulo_h\n",
    "    padding_size_v = model_divisor-modulo_v\n",
    "    \n",
    "    # get exact pixel padding for horizontal plane\n",
    "    if (padding_size_h % 2) != 0:\n",
    "        half_size_h = padding_size_h/2\n",
    "\n",
    "        left = math.floor(half_size_h)\n",
    "        right = math.ceil(half_size_h)\n",
    "    else:\n",
    "        left = int(padding_size_h/2)\n",
    "        right = int(padding_size_h/2)\n",
    "     \n",
    "    # get exact pixel padding for vertical plane\n",
    "    if (padding_size_v % 2) != 0:\n",
    "        half_size_v = padding_size_v/2\n",
    "\n",
    "        top =  math.floor(half_size_v)\n",
    "        bottom = math.ceil(half_size_v)\n",
    "    else:\n",
    "        top = int(padding_size_v/2)\n",
    "        bottom = int(padding_size_v/2)\n",
    "    \n",
    "    # pad image\n",
    "    image_pad = cv2.copyMakeBorder(image, top,bottom,left,right,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    \n",
    "    # write image\n",
    "    tifffile.imsave(im, image_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ann in annotation_paths:\n",
    "    # read mask\n",
    "    mask = cv2.imread(ann)\n",
    "    \n",
    "    # calculate padding size\n",
    "    padding_size_h = model_divisor-(mask.shape[1] % model_divisor)\n",
    "    padding_size_v = model_divisor-(mask.shape[0] % model_divisor)\n",
    "    \n",
    "    # get exact pixel padding for horizontal plane\n",
    "    if (padding_size_h % 2) != 0:\n",
    "        half_size_h = padding_size_h/2\n",
    "\n",
    "        left = math.floor(half_size_h)\n",
    "        right = math.ceil(half_size_h)\n",
    "    else:\n",
    "        left = int(padding_size_h/2)\n",
    "        right = int(padding_size_h/2)\n",
    "     \n",
    "    # get exact pixel padding for vertical plane\n",
    "    if (padding_size_v % 2) != 0:\n",
    "        half_size_v = padding_size_v/2\n",
    "\n",
    "        top =  math.floor(half_size_v)\n",
    "        bottom = math.ceil(half_size_v)\n",
    "    else:\n",
    "        top = int(padding_size_v/2)\n",
    "        bottom = int(padding_size_v/2)\n",
    "    \n",
    "    # pad mask\n",
    "    mask_pad = cv2.copyMakeBorder(mask, top,bottom,left,right,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    \n",
    "    # write mask\n",
    "    cv2.imwrite(ann, mask_pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert tif to png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im in image_paths:\n",
    "    ds=gdal.Open(im)\n",
    "    driver= gdal.GetDriverByName('PNG')\n",
    "    \n",
    "    new_path = re.sub(\"\\.tif$\",\".png\",im)\n",
    "    new_path = re.sub(\"tifs\",\"images\", new_path)\n",
    "    \n",
    "    driver.CreateCopy(new_path, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove aux files\n",
    "remove_xml = [f for f in os.listdir(\"data/trainset/large/images/\") if f.endswith('xml')]\n",
    "for x in remove_xml:\n",
    "    os.remove(\"data/trainset/large/images/\"+x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make annotations 1 pixel value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ann in annotation_paths:\n",
    "    original = cv2.imread(ann)\n",
    "    out = original.copy()\n",
    "    out[out > 0] = 1\n",
    "    cv2.imwrite(ann, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsample for medium and small datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### positive subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample for 350 en 300 & set paths\n",
    "random_m = random.sample(tif_id, 350)\n",
    "random_s = random.sample(random_m, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_list_m = [im_out_path+t+\".png\" for t in random_m]\n",
    "im_out_list_m = [im_path_m+t+\".png\" for t in random_m]\n",
    "ann_list_m = [ann_out_path+t+\".png\" for t in random_m]\n",
    "ann_out_list_m = [ann_path_m+t+\".png\" for t in random_m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy annotations to medium folder\n",
    "for ann, ann_out in zip(ann_list_m, ann_out_list_m):\n",
    "    shutil.copy(ann, ann_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy png to medium folder\n",
    "for png, png_out in zip(im_list_m, im_out_list_m):\n",
    "    shutil.copy(png, png_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_list_s = [im_out_path+t+\".png\" for t in random_s]\n",
    "im_out_list_s = [im_path_s+t+\".png\" for t in random_s]\n",
    "ann_list_s = [ann_out_path+t+\".png\" for t in random_s]\n",
    "ann_out_list_s = [ann_path_s+t+\".png\" for t in random_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy annotations to 300 folder\n",
    "for ann, ann_out in zip(ann_list_s, ann_out_list_s):\n",
    "    shutil.copy(ann, ann_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy tifs to 300 folder\n",
    "for png, png_out in zip(im_list_s, im_out_list_s):\n",
    "    shutil.copy(png, png_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### negative subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_id = [re.sub(\"\\.png$\",\"\",f) for f in os.listdir(ann_out_path) if \"negset\" in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample for 350 en 300 & set paths\n",
    "random_m_neg = random.sample(neg_id, medium_size*2)\n",
    "random_s_neg = random.sample(random_m_neg, small_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_list_m = [im_out_path+t+\".png\" for t in random_m_neg]\n",
    "im_out_list_m = [im_path_m+t+\".png\" for t in random_m_neg]\n",
    "ann_list_m = [ann_out_path+t+\".png\" for t in random_m_neg]\n",
    "ann_out_list_m = [ann_path_m+t+\".png\" for t in random_m_neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy annotations to medium folder\n",
    "for ann, ann_out in zip(ann_list_m, ann_out_list_m):\n",
    "    shutil.copy(ann, ann_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy images to medium folder\n",
    "for png, png_out in zip(im_list_m, im_out_list_m):\n",
    "    shutil.copy(png, png_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_list_s = [im_out_path+t+\".png\" for t in random_s_neg]\n",
    "im_out_list_s = [im_path_s+t+\".png\" for t in random_s_neg]\n",
    "ann_list_s = [ann_out_path+t+\".png\" for t in random_s_neg]\n",
    "ann_out_list_s = [ann_path_s+t+\".png\" for t in random_s_neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy annotations to 300 folder\n",
    "for ann, ann_out in zip(ann_list_s, ann_out_list_s):\n",
    "    shutil.copy(ann, ann_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy tifs to 300 folder\n",
    "for png, png_out in zip(im_list_s, im_out_list_s):\n",
    "    shutil.copy(png, png_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder tree for testset\n",
    "testset_path = \"data/testset/\"\n",
    "\n",
    "for lev1 in [\"0_set/\",\"1_set/\"]:\n",
    "    for lev2 in [\"images\",\"annotations\", \"tifs\"]:\n",
    "        path = testset_path+lev1+lev2\n",
    "        os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to test set folder\n",
    "\n",
    "# positive\n",
    "pos_test_im = testset_path+\"1_set/images/\"\n",
    "pos_test_tifs = testset_path+\"1_set/tifs/\"\n",
    "\n",
    "# negative\n",
    "neg_test_im = testset_path+\"0_set/images/\"\n",
    "neg_test_tifs = testset_path+\"0_set/tifs/\"\n",
    "neg_test_ann = testset_path+\"0_set/annotations/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset id's\n",
    "trainset = [re.sub(\"\\.tif$\",\"\", f) for f in os.listdir(tif_out_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random draw from 1-set not in trainset\n",
    "pos_tifs = [f for f in os.listdir(tif_folder) if re.sub(\"\\.tif$\",\"\", f) not in trainset]\n",
    "neg_tifs = [f for f in os.listdir(tif_folder_0) if re.sub(\"\\.tif$\",\"\", f) not in trainset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random draw from positive and negative tifs\n",
    "pos_draw = random.sample(pos_tifs, 250)\n",
    "neg_draw = random.sample(neg_tifs, 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create full paths\n",
    "pos_in = [tif_folder+f for f in pos_draw]\n",
    "neg_in = [tif_folder_0+\"negset_\"+f for f in neg_draw]\n",
    "\n",
    "pos_out = [pos_test_tifs+f for f in pos_draw]\n",
    "neg_out = [neg_test_tifs+\"negset_\"+f for f in neg_draw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create image folder\n",
    "pos_im_out = [pos_test_im+f for f in pos_draw]\n",
    "neg_im_out = [neg_test_im+f for f in neg_draw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy tifs to pos folder\n",
    "for pos_in, pos_out in zip(pos_in, pos_out):\n",
    "    shutil.copy(pos_in, pos_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy tifs to neg folder\n",
    "for neg_in, neg_out in zip(neg_in, neg_out):\n",
    "    shutil.copy(neg_in, neg_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pad tifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im in pos_out:\n",
    "    # read image\n",
    "    image = tifffile.imread(im)\n",
    "    \n",
    "    # calculate padding size\n",
    "    modulo_h = image.shape[1] % model_divisor\n",
    "    modulo_v = image.shape[0] % model_divisor\n",
    "    \n",
    "    if(modulo_h == 0)&(modulo_v == 0):\n",
    "        continue\n",
    "    \n",
    "    padding_size_h = model_divisor-modulo_h\n",
    "    padding_size_v = model_divisor-modulo_v\n",
    "    \n",
    "    # get exact pixel padding for horizontal plane\n",
    "    if (padding_size_h % 2) != 0:\n",
    "        half_size_h = padding_size_h/2\n",
    "\n",
    "        left = math.floor(half_size_h)\n",
    "        right = math.ceil(half_size_h)\n",
    "    else:\n",
    "        left = int(padding_size_h/2)\n",
    "        right = int(padding_size_h/2)\n",
    "     \n",
    "    # get exact pixel padding for vertical plane\n",
    "    if (padding_size_v % 2) != 0:\n",
    "        half_size_v = padding_size_v/2\n",
    "\n",
    "        top =  math.floor(half_size_v)\n",
    "        bottom = math.ceil(half_size_v)\n",
    "    else:\n",
    "        top = int(padding_size_v/2)\n",
    "        bottom = int(padding_size_v/2)\n",
    "    \n",
    "    # pad image\n",
    "    image_pad = cv2.copyMakeBorder(image, top,bottom,left,right,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    \n",
    "    # write image\n",
    "    tifffile.imsave(im, image_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im in neg_out:\n",
    "    # read image\n",
    "    image = tifffile.imread(im)\n",
    "    \n",
    "    # calculate padding size\n",
    "    modulo_h = image.shape[1] % model_divisor\n",
    "    modulo_v = image.shape[0] % model_divisor\n",
    "    \n",
    "    if(modulo_h == 0)&(modulo_v == 0):\n",
    "        continue\n",
    "    \n",
    "    padding_size_h = model_divisor-modulo_h\n",
    "    padding_size_v = model_divisor-modulo_v\n",
    "    \n",
    "    # get exact pixel padding for horizontal plane\n",
    "    if (padding_size_h % 2) != 0:\n",
    "        half_size_h = padding_size_h/2\n",
    "\n",
    "        left = math.floor(half_size_h)\n",
    "        right = math.ceil(half_size_h)\n",
    "    else:\n",
    "        left = int(padding_size_h/2)\n",
    "        right = int(padding_size_h/2)\n",
    "     \n",
    "    # get exact pixel padding for vertical plane\n",
    "    if (padding_size_v % 2) != 0:\n",
    "        half_size_v = padding_size_v/2\n",
    "\n",
    "        top =  math.floor(half_size_v)\n",
    "        bottom = math.ceil(half_size_v)\n",
    "    else:\n",
    "        top = int(padding_size_v/2)\n",
    "        bottom = int(padding_size_v/2)\n",
    "    \n",
    "    # pad image\n",
    "    image_pad = cv2.copyMakeBorder(image, top,bottom,left,right,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    \n",
    "    # write image\n",
    "    tifffile.imsave(im, image_pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pos_draw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-2d0bbe8054d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# create image folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpos_im_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpos_test_im\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\.tif$\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\".png\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpos_draw\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mneg_im_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mneg_test_im\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\.tif$\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\".png\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mneg_draw\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pos_draw' is not defined"
     ]
    }
   ],
   "source": [
    "# create image folder\n",
    "pos_im_out = [pos_test_im+re.sub(\"\\.tif$\",\".png\", f) for f in pos_draw]\n",
    "neg_im_out = [neg_test_im+re.sub(\"\\.tif$\",\".png\", f) for f in neg_draw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im_in, im_out in zip(pos_out, pos_im_out):\n",
    "    ds=gdal.Open(im_in)\n",
    "    driver= gdal.GetDriverByName('PNG')\n",
    "    \n",
    "    driver.CreateCopy(im_out, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove aux files\n",
    "remove_xml = [f for f in os.listdir(\"data/testset/1_set/images/\") if f.endswith('xml')]\n",
    "for x in remove_xml:\n",
    "    os.remove(\"data/testset/1_set/images/\"+x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im_in, im_out in zip(neg_out, neg_im_out):\n",
    "    ds=gdal.Open(im_in)\n",
    "    driver= gdal.GetDriverByName('PNG')\n",
    "    \n",
    "    driver.CreateCopy(im_out, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove aux files\n",
    "remove_xml = [f for f in os.listdir(\"data/testset/0_set/images/\") if f.endswith('xml')]\n",
    "for x in remove_xml:\n",
    "    os.remove(\"data/testset/0_set/images/\"+x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 0-set annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_array = cv2.imread(neg_im_out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 0-set annotations\n",
    "\n",
    "# get size of sample image\n",
    "neg_array = cv2.imread(neg_im_out[0])\n",
    "\n",
    "# make all black array for mask\n",
    "neg_array.fill(0)\n",
    "\n",
    "# create full annotation path\n",
    "neg_annotation_paths = [re.sub(\"images\",\"annotations\", f) for f in neg_im_out]\n",
    "\n",
    "for annotation in neg_annotation_paths:\n",
    "    cv2.imwrite(annotation, neg_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# errorfix: negset in filename\n",
    "neg = [\"data/testset/annotations/\"+f for f in neg]\n",
    "neglist = os.listdir(\"data/testset/0_set/annotations/\")\n",
    "neglist = [\"data/testset/annotations/\"+f for f in neglist]\n",
    "\n",
    "for f in neglist:\n",
    "    newname = re.sub(\"\\/(?=\\d)\",\"/negset_\", f)\n",
    "    os.rename(f, newname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get annotations from zip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_raw_folder_test = \"data/1_set_test_annotated/\"\n",
    "ann_out_path_test = \"data/testset/1_set/annotations/\"\n",
    "ann_out_path_test_g = \"data/testset/annotation_groups/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all zip files\n",
    "ann_raw_paths_test = [join(ann_raw_folder_test,f) for f in os.listdir(ann_raw_folder_test) if f.endswith('.zip')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/1_set_test_annotated/task_test1-2021_07_21_15_28_17-segmentation mask 1.1.zip',\n",
       " 'data/1_set_test_annotated/task_test2-2021_07_21_09_11_05-segmentation mask 1.1.zip',\n",
       " 'data/1_set_test_annotated/task_test3-2021_07_21_09_39_06-segmentation mask 1.1.zip',\n",
       " 'data/1_set_test_annotated/task_test4-2021_07_21_12_18_12-segmentation mask 1.1.zip',\n",
       " 'data/1_set_test_annotated/task_test5-2021_07_21_13_05_42-segmentation mask 1.1.zip',\n",
       " 'data/1_set_test_annotated/task_test6-2021_07_21_14_37_52-segmentation mask 1.1.zip',\n",
       " 'data/1_set_test_annotated/task_test7-2021_07_21_14_43_54-segmentation mask 1.1.zip',\n",
       " 'data/1_set_test_annotated/task_test8-2021_07_21_15_24_32-segmentation mask 1.1.zip']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.makedirs(ann_out_path_test = \"data/testset/1_set/annotations/\")\n",
    "os.makedirs(ann_out_path_test_g = \"data/testset/annotation_groups/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all content of Segmentationclass folder for each zip\n",
    "for filepath in ann_raw_paths_test:\n",
    "    obj = ZipFile(filepath, 'r')\n",
    "    filelist = obj.namelist()\n",
    "    for file in filelist:\n",
    "        if file.startswith(\"SegmentationClass\"):\n",
    "            obj.extract(file, path=ann_out_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move all files 1 level up\n",
    "segmentation_path = os.listdir(ann_out_path_test+\"SegmentationClass\")\n",
    "\n",
    "for mask in segmentation_path:\n",
    "    shutil.move(ann_out_path_test+\"SegmentationClass/\"+mask, ann_out_path_test+mask)\n",
    "    \n",
    "# remove folder\n",
    "os.removedirs(ann_out_path_test+\"SegmentationClass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same for annotation grouped\n",
    "for filepath in ann_raw_paths_test:\n",
    "    obj = ZipFile(filepath, 'r')\n",
    "    filelist = obj.namelist()\n",
    "    for file in filelist:\n",
    "        if file.startswith(\"SegmentationObject\"):\n",
    "            obj.extract(file, path=ann_out_path_test_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move all files 1 level up\n",
    "segmentation_path = os.listdir(ann_out_path_test_g+\"SegmentationObject\")\n",
    "\n",
    "for mask in segmentation_path:\n",
    "    shutil.move(ann_out_path_test_g+\"SegmentationObject/\"+mask, ann_out_path_test_g+mask)\n",
    "    \n",
    "# remove folder\n",
    "os.removedirs(ann_out_path_test_g+\"SegmentationObject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy negset to annotation groups\n",
    "negset = [f for f in os.listdir(\"data/testset/annotations\") if \"negset\" in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in negset:\n",
    "    shutil.copy(\"data/testset/annotations/\"+f, \"data/testset/annotation_groups/\"+f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge 0-set and 1-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(testset_path+\"images/\")\n",
    "os.makedirs(testset_path+\"annotations/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lev1 in [\"0_set/\",\"1_set/\"]:\n",
    "    for lev2 in [\"images/\",\"annotations/\"]:\n",
    "        files = os.listdir(testset_path+lev1+lev2)\n",
    "        for f in files:\n",
    "            shutil.move(testset_path+lev1+lev2+f, testset_path+lev2+f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg =  [f for f in os.listdir(\"data/testset/annotations/\")]\n",
    "neg = [\"data/testset/annotations/\"+f for f in neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "neglist = []\n",
    "for f in neg:\n",
    "    file = cv2.imread(f)\n",
    "    if np.sum(file) == 0:\n",
    "        neglist.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction path\n",
    "os.makedirs(testset_path+\"predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make alternative annotations 1 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_path_in =  [f for f in os.listdir(\"data/testset/annotations/\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ann in ann_path_in:\n",
    "    original = cv2.imread(\"data/testset/annotations/\"+ann)\n",
    "    out = original.copy()\n",
    "    out[out > 0] = 1\n",
    "    cv2.imwrite(\"data/testset/alt_annotations/\"+ann, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### negative set naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data path for images\n",
    "#image_path = \"data/testset/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of image files and create input path\n",
    "#im_files = os.listdir(image_path)\n",
    "#input_path = [image_path+f for f in os.listdir(image_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of annotations, for negset list\n",
    "#ann_files = [re.sub(\"negset_\",\"\", f) for f in os.listdir(\"../data/testset/annotations/\") if \"negset\" in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for f in im_files:\n",
    "#    if f in ann_files:\n",
    "#        os.rename(image_path+f, image_path+\"negset_\"+f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
