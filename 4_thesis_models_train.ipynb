{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras_segmentation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fc3b591876e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras_segmentation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfcn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfcn_8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcn_32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcn_8_vgg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcn_32_vgg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcn_8_resnet50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcn_32_resnet50\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras_segmentation'"
     ]
    }
   ],
   "source": [
    "from keras_segmentation.models.fcn import fcn_8, fcn_32, fcn_8_vgg, fcn_32_vgg, fcn_8_resnet50, fcn_32_resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from shutil import copyfile\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "from google.colab import files\n",
    "import tensorflow as tf\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "import shutil\n",
    "from os.path import basename\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\r\n",
      "      - Validating: \u001b[32mOK\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# This is required for me to have autocomplete\n",
    "%config Completer.use_jedi = False\n",
    "%matplotlib inline\n",
    "\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test GPU enabled\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdrive = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths for normal use\n",
    "if gdrive == False:\n",
    "    base_path = \"../\"\n",
    "else:\n",
    "    base_path = \"/content/gdrive/MyDrive/data_science/MBA/Thesis/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "    \n",
    "# set path to trainset\n",
    "data_path = base_path+\"data/trainset/\"\n",
    "\n",
    "# set path for checkpoints\n",
    "checkpoint_path = base_path+\"data/train_checkpoints/\"\n",
    "\n",
    "# set path for final checkpoints\n",
    "trainset_final_path = base_path+\"data/train_final_checkpoints/\"\n",
    "\n",
    "# dataset sizes (for looping)\n",
    "sizes = [\"small\",\"medium\",\"large\",\"small_transform\",\"medium_transform\",\"large_transform\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model parameters\n",
    "model_params = {\"input_height\": 800,\n",
    "                \"input_width\": 800,\n",
    "                \"n_classes\" : 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set models\n",
    "Vanilla8 = fcn_8(**model_params)\n",
    "Vanilla32 = fcn_32(**model_params)\n",
    "VGG8 = fcn_8_vgg(**model_params)\n",
    "VGG32 = fcn_32_vgg(**model_params)\n",
    "Resnet8 = fcn_8_resnet50(**model_params)\n",
    "Resnet32 = fcn_32_resnet50(**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model dict\n",
    "models = {\"Vanilla8\": Vanilla8,\n",
    "         \"Vanilla32\": Vanilla32,\n",
    "         \"VGG8\": VGG8,\n",
    "         \"VGG32\": VGG32,\n",
    "         \"Restnet8\": Resnet8,\n",
    "         \"Restnet32\": Resnet32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directories for training\n",
    "for model in models.keys():\n",
    "    for size in sizes:\n",
    "        size = \"/\"+size\n",
    "        os.makedirs(checkpoint_path+model+size, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder tree for final epoch predictions\n",
    "for model in models.keys():\n",
    "    path = trainset_final_path+model\n",
    "    os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model Vanilla8 with dataset size large_transform\n",
      "Epoch 1/5\n",
      "512/512 [==============================] - 1867s 4s/step - loss: 0.0053 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00001: saving model to ../data/train_checkpoints/Vanilla8/large_transform/Vanilla8_large_transform_weights.00001\n",
      "Epoch 2/5\n",
      "512/512 [==============================] - 1871s 4s/step - loss: 0.0038 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00002: saving model to ../data/train_checkpoints/Vanilla8/large_transform/Vanilla8_large_transform_weights.00002\n",
      "Epoch 3/5\n",
      "512/512 [==============================] - 1837s 4s/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00003: saving model to ../data/train_checkpoints/Vanilla8/large_transform/Vanilla8_large_transform_weights.00003\n",
      "Epoch 4/5\n",
      "512/512 [==============================] - 1837s 4s/step - loss: 0.0031 - accuracy: 0.9989\n",
      "\n",
      "Epoch 00004: saving model to ../data/train_checkpoints/Vanilla8/large_transform/Vanilla8_large_transform_weights.00004\n",
      "Epoch 5/5\n",
      "512/512 [==============================] - 1834s 4s/step - loss: 0.0045 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00005: saving model to ../data/train_checkpoints/Vanilla8/large_transform/Vanilla8_large_transform_weights.00005\n",
      "training model Vanilla32 with dataset size small\n",
      "Epoch 1/5\n",
      "512/512 [==============================] - 1837s 4s/step - loss: 0.1299 - accuracy: 0.9466\n",
      "\n",
      "Epoch 00001: saving model to ../data/train_checkpoints/Vanilla32/small/Vanilla32_small_weights.00001\n",
      "Epoch 2/5\n",
      "512/512 [==============================] - 1847s 4s/step - loss: 0.0257 - accuracy: 0.9905\n",
      "\n",
      "Epoch 00002: saving model to ../data/train_checkpoints/Vanilla32/small/Vanilla32_small_weights.00002\n",
      "Epoch 3/5\n",
      "512/512 [==============================] - 1861s 4s/step - loss: 0.0212 - accuracy: 0.9922\n",
      "\n",
      "Epoch 00003: saving model to ../data/train_checkpoints/Vanilla32/small/Vanilla32_small_weights.00003\n",
      "Epoch 4/5\n",
      "512/512 [==============================] - 1842s 4s/step - loss: 0.0175 - accuracy: 0.9934\n",
      "\n",
      "Epoch 00004: saving model to ../data/train_checkpoints/Vanilla32/small/Vanilla32_small_weights.00004\n",
      "Epoch 5/5\n",
      "512/512 [==============================] - 1850s 4s/step - loss: 0.0150 - accuracy: 0.9940\n",
      "\n",
      "Epoch 00005: saving model to ../data/train_checkpoints/Vanilla32/small/Vanilla32_small_weights.00005\n",
      "training model Vanilla32 with dataset size medium\n",
      "Epoch 1/5\n",
      "512/512 [==============================] - 1837s 4s/step - loss: 0.0185 - accuracy: 0.9929\n",
      "\n",
      "Epoch 00001: saving model to ../data/train_checkpoints/Vanilla32/medium/Vanilla32_medium_weights.00001\n",
      "Epoch 2/5\n",
      "512/512 [==============================] - 1830s 4s/step - loss: 0.0149 - accuracy: 0.9940\n",
      "\n",
      "Epoch 00002: saving model to ../data/train_checkpoints/Vanilla32/medium/Vanilla32_medium_weights.00002\n",
      "Epoch 3/5\n",
      "512/512 [==============================] - 1835s 4s/step - loss: 0.0141 - accuracy: 0.9942\n",
      "\n",
      "Epoch 00003: saving model to ../data/train_checkpoints/Vanilla32/medium/Vanilla32_medium_weights.00003\n",
      "Epoch 4/5\n",
      "512/512 [==============================] - 1833s 4s/step - loss: 0.0123 - accuracy: 0.9948\n",
      "\n",
      "Epoch 00004: saving model to ../data/train_checkpoints/Vanilla32/medium/Vanilla32_medium_weights.00004\n",
      "Epoch 5/5\n",
      "512/512 [==============================] - 1833s 4s/step - loss: 0.0120 - accuracy: 0.9950\n",
      "\n",
      "Epoch 00005: saving model to ../data/train_checkpoints/Vanilla32/medium/Vanilla32_medium_weights.00005\n",
      "training model Vanilla32 with dataset size large\n",
      "Epoch 1/5\n",
      "512/512 [==============================] - 1830s 4s/step - loss: 0.0067 - accuracy: 0.9977\n",
      "\n",
      "Epoch 00001: saving model to ../data/train_checkpoints/Vanilla32/large/Vanilla32_large_weights.00001\n",
      "Epoch 2/5\n",
      "512/512 [==============================] - 1833s 4s/step - loss: 0.0076 - accuracy: 0.9975\n",
      "\n",
      "Epoch 00002: saving model to ../data/train_checkpoints/Vanilla32/large/Vanilla32_large_weights.00002\n",
      "Epoch 3/5\n",
      "512/512 [==============================] - 1833s 4s/step - loss: 0.0078 - accuracy: 0.9976\n",
      "\n",
      "Epoch 00003: saving model to ../data/train_checkpoints/Vanilla32/large/Vanilla32_large_weights.00003\n",
      "Epoch 4/5\n",
      "512/512 [==============================] - 1832s 4s/step - loss: 0.0056 - accuracy: 0.9979\n",
      "\n",
      "Epoch 00004: saving model to ../data/train_checkpoints/Vanilla32/large/Vanilla32_large_weights.00004\n",
      "Epoch 5/5\n",
      "512/512 [==============================] - 1833s 4s/step - loss: 0.0050 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00005: saving model to ../data/train_checkpoints/Vanilla32/large/Vanilla32_large_weights.00005\n",
      "training model Vanilla32 with dataset size small_transform\n",
      "Epoch 1/5\n",
      "512/512 [==============================] - 1840s 4s/step - loss: 0.0147 - accuracy: 0.9947\n",
      "\n",
      "Epoch 00001: saving model to ../data/train_checkpoints/Vanilla32/small_transform/Vanilla32_small_transform_weights.00001\n",
      "Epoch 2/5\n",
      "512/512 [==============================] - 1835s 4s/step - loss: 0.0123 - accuracy: 0.9949\n",
      "\n",
      "Epoch 00002: saving model to ../data/train_checkpoints/Vanilla32/small_transform/Vanilla32_small_transform_weights.00002\n",
      "Epoch 3/5\n",
      "512/512 [==============================] - 1833s 4s/step - loss: 0.0112 - accuracy: 0.9953\n",
      "\n",
      "Epoch 00003: saving model to ../data/train_checkpoints/Vanilla32/small_transform/Vanilla32_small_transform_weights.00003\n",
      "Epoch 4/5\n",
      "512/512 [==============================] - 1826s 4s/step - loss: 0.0102 - accuracy: 0.9957\n",
      "\n",
      "Epoch 00004: saving model to ../data/train_checkpoints/Vanilla32/small_transform/Vanilla32_small_transform_weights.00004\n",
      "Epoch 5/5\n",
      "512/512 [==============================] - 1833s 4s/step - loss: 0.0099 - accuracy: 0.9958\n",
      "\n",
      "Epoch 00005: saving model to ../data/train_checkpoints/Vanilla32/small_transform/Vanilla32_small_transform_weights.00005\n",
      "training model Vanilla32 with dataset size medium_transform\n",
      "Epoch 1/5\n",
      "512/512 [==============================] - 1828s 4s/step - loss: 0.0135 - accuracy: 0.9947\n",
      "\n",
      "Epoch 00001: saving model to ../data/train_checkpoints/Vanilla32/medium_transform/Vanilla32_medium_transform_weights.00001\n",
      "Epoch 2/5\n",
      "512/512 [==============================] - 1824s 4s/step - loss: 0.0112 - accuracy: 0.9954\n",
      "\n",
      "Epoch 00002: saving model to ../data/train_checkpoints/Vanilla32/medium_transform/Vanilla32_medium_transform_weights.00002\n",
      "Epoch 3/5\n",
      "512/512 [==============================] - 1826s 4s/step - loss: 0.0107 - accuracy: 0.9955\n",
      "\n",
      "Epoch 00003: saving model to ../data/train_checkpoints/Vanilla32/medium_transform/Vanilla32_medium_transform_weights.00003\n",
      "Epoch 4/5\n",
      "512/512 [==============================] - 1832s 4s/step - loss: 0.0096 - accuracy: 0.9959\n",
      "\n",
      "Epoch 00004: saving model to ../data/train_checkpoints/Vanilla32/medium_transform/Vanilla32_medium_transform_weights.00004\n",
      "Epoch 5/5\n",
      " 64/512 [==>...........................] - ETA: 26:56 - loss: 0.0111 - accuracy: 0.9953"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-6e34b7cc9d21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mtrain_annotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mannotation_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mcheckpoints_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpnt_path\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                 \u001b[0mverify_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             )\n\u001b[1;32m     20\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_segmentation/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_images, train_annotations, input_height, input_width, n_classes, verify_dataset, checkpoints_path, epochs, batch_size, validate, val_images, val_annotations, val_batch_size, auto_resume_checkpoint, load_weights, steps_per_epoch, val_steps_per_epoch, gen_use_multiprocessing, ignore_zero_class, optimizer_name, do_augment, augmentation_name, callbacks, custom_augmentation, other_inputs_paths, preprocessing, read_image_type)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         model.fit(train_gen, steps_per_epoch=steps_per_epoch,\n\u001b[0;32m--> 201\u001b[0;31m                   epochs=epochs, callbacks=callbacks, initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         model.fit(train_gen,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train models\n",
    "for model_name, model in models.items():\n",
    "    for size in sizes:\n",
    "        print(\"training model \"+model_name+\" with dataset size \"+size)\n",
    "        train_path = data_path+size+\"/images/\"\n",
    "        annotation_path = data_path+size+\"/annotations/\"\n",
    "        checkpnt_path = checkpoint_path+model_name+\"/\"+size+\"/\"+model_name+\"_\"+size+\"_weights\"\n",
    "        \n",
    "        model.train(\n",
    "            train_images =  train_path,\n",
    "            train_annotations = annotation_path,\n",
    "            checkpoints_path = checkpnt_path , \n",
    "            epochs=5,\n",
    "            verify_dataset=False\n",
    "        )\n",
    "        shutil.make_archive(base_path+\"data/train_checkpoints/\"+model_name, 'zip',\n",
    "                    base_path+\"data/train_checkpoints/+model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/train_checkpoints/Vanilla8/small/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-050906a7f8cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mout_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainset_final_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mf_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"00005.\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/train_checkpoints/Vanilla8/small/'"
     ]
    }
   ],
   "source": [
    "# loop over training files and copy final epoch\n",
    "for model in [\"VGG32\", \"VGG8\", \"Vanilla8\", \"Vanilla32\"]:\n",
    "    for size in sizes:\n",
    "        \n",
    "        in_files = checkpoint_path+model+\"/\"+size+\"/\"\n",
    "        out_files = trainset_final_path+model+\"/\"+size+\"/\"\n",
    "        \n",
    "        files = os.listdir(in_files)\n",
    "        f_file = [f for f in files if \"00005.\" in f]\n",
    "        \n",
    "        for f in f_file:\n",
    "            shutil.copy(in_files+f, out_files+f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['small/Vanilla8_small_weights.00005.data-00000-of-00001', 'small/Vanilla8_small_weights.00005.index', 'medium/Vanilla8_medium_weights.00005.data-00000-of-00001', 'medium/Vanilla8_medium_weights.00005.index', 'large/Vanilla8_large_weights.00005.data-00000-of-00001', 'large/Vanilla8_large_weights.00005.index', 'small_transform/Vanilla8_small_transform_weights.00005.data-00000-of-00001', 'small_transform/Vanilla8_small_transform_weights.00005.index', 'medium_transform/Vanilla8_medium_transform_weights.00005.data-00000-of-00001', 'medium_transform/Vanilla8_medium_transform_weights.00005.index', 'large_transform/Vanilla8_large_transform_weights.00005.data-00000-of-00001', 'large_transform/Vanilla8_large_transform_weights.00005.index', 'small/Vanilla8_small_weights_config.json', 'medium/Vanilla8_medium_weights_config.json', 'large/Vanilla8_large_weights_config.json', 'small_transform/Vanilla8_small_transform_weights_config.json', 'medium_transform/Vanilla8_medium_transform_weights_config.json', 'large_transform/Vanilla8_large_transform_weights_config.json']\n"
     ]
    }
   ],
   "source": [
    "for model_name in [\"Vanilla8\"]:#[\"VGG32\", \"VGG8\", \"Vanilla32\", \"Restnet8\",\"Restnet32\"]:\n",
    "    zipfile_path = checkpoint_path+model_name+\".zip\"\n",
    "\n",
    "    with ZipFile(zipfile_path, 'r') as zipObj:\n",
    "        listOfFileNames = zipObj.namelist()\n",
    "        list1 = [f for f in listOfFileNames if \"00005.\" in f]\n",
    "        list2 = [f for f in listOfFileNames if \".json\" in f]\n",
    "        finallist = list1+list2\n",
    "        print(finallist)\n",
    "        \n",
    "        # Restnet 8 and 32 is zipped differently\n",
    "        for f in finallist:\n",
    "            if model_name in [\"Restnet8\",\"Restnet32\"]:\n",
    "                zipObj.extract(f ,'../data/train_final_checkpoints2/')\n",
    "            else:\n",
    "                zipObj.extract(f ,'../data/train_final_checkpoints2/'+model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over prediction files and copy final epoch\n",
    "for model in [\"VGG32\", \"VGG8\", \"Vanilla8\", \"Vanilla32\"]:\n",
    "    for size in sizes:\n",
    "        \n",
    "        zipfile_path = checkpoint_path+model\n",
    "        \n",
    "        with ZipFile(zipfile_path, 'r') as zipObj:\n",
    "        \n",
    "        in_files = checkpoint_path+model+\"/\"+size+\"/\"\n",
    "        out_files = trainset_final_path+model+\"/\"+size+\"/\"\n",
    "        \n",
    "        files = os.listdir(in_files)\n",
    "        f_file = [f for f in files if f.endswith(\"config.json\")]\n",
    "        \n",
    "        for f in f_file:\n",
    "            shutil.copy(in_files+f, out_files+f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
